import streamlit as st
import pandas as pd
import re
from datetime import datetime
import time
import yt_dlp
import io
import requests
import xml.etree.ElementTree as ET

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="å‹•ç”»é¸å‡ºé›†è¨ˆãƒ„ãƒ¼ãƒ«", layout="wide")

# --- å®šæ•°ãƒ»æ­£è¦è¡¨ç¾ ---
NICO_ID_RE = re.compile(r'(sm\d+|so\d+|nm\d+)')

def get_nico_metadata_api(video_id):
    """ãƒ‹ã‚³ãƒ‹ã‚³å‹•ç”»ã®å…¬å¼å¤–éƒ¨API(getthumbinfo)ã‹ã‚‰æƒ…å ±ã‚’å–å¾—ã™ã‚‹"""
    api_url = f"https://ext.nicovideo.jp/api/getthumbinfo/{video_id}"
    try:
        response = requests.get(api_url, timeout=5)
        if response.status_code == 200:
            root = ET.fromstring(response.text)
            if root.get('status') == 'ok':
                thumb = root.find('thumb')
                # æŠ•ç¨¿æ—¥æ™‚ (2024-01-01T00:00:00+09:00 å½¢å¼)
                raw_date = thumb.find('first_retrieve').text
                # YYYY-MM-DD HH:MM:SS å½¢å¼ã«æ•´å½¢
                dt = datetime.fromisoformat(raw_date)
                return {
                    'video_id': video_id,
                    'title': thumb.find('title').text,
                    'uploader': thumb.find('user_nickname').text if thumb.find('user_nickname') is not None else "å…¬å¼/ä¸æ˜",
                    'upload_date': dt.strftime('%Y-%m-%d %H:%M:%S'),
                    'url': f"https://www.nicovideo.jp/watch/{video_id}"
                }
    except Exception:
        pass
    return None

def get_video_metadata(url):
    """yt-dlpã‚’ä½¿ç”¨ã—ã¦æƒ…å ±ã‚’å–å¾—ã—ã€ãƒ‹ã‚³ãƒ‹ã‚³ã®å ´åˆã¯å°‚ç”¨APIã§è£œå®Œã™ã‚‹"""
    # ãƒ‹ã‚³ãƒ‹ã‚³ã®IDãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    nico_ids = NICO_ID_RE.findall(url)
    if nico_ids:
        # æœ€åˆã®IDã«å¯¾ã—ã¦å°‚ç”¨APIã‚’è©¦ã¿ã‚‹
        data = get_nico_metadata_api(nico_ids[0])
        if data:
            return [data]

    # ãƒ‹ã‚³ãƒ‹ã‚³ä»¥å¤–ï¼ˆYouTubeãªã©ï¼‰ã‚„APIå¤±æ•—æ™‚ã®ãŸã‚ã®é€šå¸¸å‡¦ç†
    ydl_opts = {
        'quiet': True,
        'no_warnings': True,
        'extract_flat': True,
        'skip_download': True,
    }
    
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            
            if 'entries' in info:
                videos = []
                for entry in info['entries']:
                    if entry:
                        v_id = entry.get('id')
                        # ãƒã‚¤ãƒªã‚¹ãƒˆå†…ã®å„å‹•ç”»ã«ã¤ã„ã¦ã‚‚ãƒ‹ã‚³ãƒ‹ã‚³ãªã‚‰APIã‚’è©¦ã¿ã‚‹
                        if v_id and (v_id.startswith('sm') or v_id.startswith('so')):
                            nico_data = get_nico_metadata_api(v_id)
                            if nico_data:
                                videos.append(nico_data)
                                continue
                        
                        videos.append({
                            'video_id': v_id or entry.get('url'),
                            'title': entry.get('title') or "[ã‚¿ã‚¤ãƒˆãƒ«å–å¾—ä¸å¯]",
                            'uploader': entry.get('uploader') or entry.get('channel') or "[æŠ•ç¨¿è€…ä¸æ˜]",
                            'upload_date': format_date(entry.get('upload_date')),
                            'url': entry.get('url') or f"https://www.nicovideo.jp/watch/{v_id}"
                        })
                return videos
            else:
                return [{
                    'video_id': info.get('id'),
                    'title': info.get('title') or "[ã‚¿ã‚¤ãƒˆãƒ«å–å¾—ä¸å¯]",
                    'uploader': info.get('uploader') or info.get('channel') or "[æŠ•ç¨¿è€…ä¸æ˜]",
                    'upload_date': format_date(info.get('upload_date')),
                    'url': url
                }]
    except Exception:
        return None

def format_date(date_str):
    """YYYYMMDD å½¢å¼ã‚’ YYYY-MM-DD HH:MM:SS ã«å¤‰æ›"""
    if not date_str or not isinstance(date_str, str):
        return "[ä¸æ˜]"
    try:
        # yyyymmdd å½¢å¼
        if len(date_str) == 8:
            dt = datetime.strptime(date_str, '%Y%m%d')
            return dt.strftime('%Y-%m-%d %H:%M:%S')
    except:
        pass
    return date_str

def process_data(df):
    """CSVå…¨ä½“ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    all_votes = []
    video_meta_cache = {} 
    
    progress_text = "å‹•ç”»æƒ…å ±ã‚’è§£æä¸­..."
    progress_bar = st.progress(0, text=progress_text)
    total_rows = len(df)

    for i, row in df.iterrows():
        respondent = str(row.iloc[1]) if len(row) > 1 else "åŒ¿å"
        mylist_url = str(row.iloc[3]) if len(row) > 3 else ""
        ext_url = str(row.iloc[4]) if len(row) > 4 else ""

        urls_to_process = [u.strip() for u in [mylist_url, ext_url] if u.strip() and u != 'nan']
        
        for url in urls_to_process:
            if url in video_meta_cache:
                results = video_meta_cache[url]
            else:
                results = get_video_metadata(url)
                video_meta_cache[url] = results
                time.sleep(0.05) # APIè² è·è»½æ¸›ï¼ˆãƒ‹ã‚³ãƒ‹ã‚³APIã¯è»½é‡ãªã®ã§çŸ­ã‚ã§OKï¼‰

            if results:
                for v in results:
                    all_votes.append({
                        'video_id': v['video_id'],
                        'title': v['title'],
                        'uploader': v['uploader'],
                        'upload_date': v['upload_date'],
                        'respondent': respondent
                    })
            else:
                # å–å¾—ä¸å¯ã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                nico_ids = NICO_ID_RE.findall(url)
                if nico_ids:
                    for n_id in nico_ids:
                        all_votes.append({
                            'video_id': n_id, 'title': "[å–å¾—ä¸å¯]", 'uploader': "[å–å¾—ä¸å¯]",
                            'upload_date': "[å–å¾—ä¸å¯]", 'respondent': respondent
                        })

        progress_bar.progress((i + 1) / total_rows, text=f"{progress_text} ({i+1}/{total_rows}è¡Œç›®)")

    if not all_votes: return None

    votes_df = pd.DataFrame(all_votes)
    ranking = votes_df.groupby('video_id').agg({
        'title': 'first', 'upload_date': 'first', 'uploader': 'first',
        'respondent': lambda x: sorted(list(set(x)))
    }).reset_index()

    ranking['count'] = ranking['respondent'].apply(len)
    ranking = ranking.sort_values(by=['count', 'video_id'], ascending=[False, True])
    ranking['é †ä½(è¢«ã‚Šãªã—)'] = range(1, len(ranking) + 1)
    ranking['é †ä½(è¢«ã‚Šã‚ã‚Š)'] = ranking['count'].rank(ascending=False, method='min').astype(int)
    
    return ranking

# --- UI ---
st.title("ğŸ“Š å‹•ç”»é¸å‡ºé›†è¨ˆãƒ»ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«")
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['csv'])

if uploaded_file:
    content = uploaded_file.read()
    try:
        df_input = pd.read_csv(io.BytesIO(content), encoding='utf-8')
    except:
        df_input = pd.read_csv(io.BytesIO(content), encoding='shift-jis')

    if st.button("ğŸš€ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œæˆã™ã‚‹"):
        result_df = process_data(df_input)
        if result_df is not None:
            max_voters = result_df['count'].max()
            voter_cols = [f"é¸å‡ºè€…{i+1}" for i in range(max_voters)]
            voters_expanded = pd.DataFrame(result_df['respondent'].tolist(), index=result_df.index).iloc[:, :max_voters]
            voters_expanded.columns = voter_cols[:len(voters_expanded.columns)]

            final_output = pd.concat([
                result_df[['é †ä½(è¢«ã‚Šãªã—)', 'é †ä½(è¢«ã‚Šã‚ã‚Š)', 'title', 'video_id', 'upload_date', 'uploader']],
                voters_expanded
            ], axis=1)

            final_output = final_output.rename(columns={
                'title': 'å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«', 'video_id': 'å‹•ç”»ID', 'upload_date': 'æŠ•ç¨¿æ—¥æ™‚', 'uploader': 'æŠ•ç¨¿è€…'
            })

            st.success("é›†è¨ˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            st.subheader("ğŸ† é›†è¨ˆçµæœãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            st.dataframe(final_output)
            csv_data = final_output.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv_data, file_name=f"ranking.csv", mime='text/csv')

import streamlit as st
import pandas as pd
import re
from datetime import datetime
import time
import yt_dlp
import io
import requests
import xml.etree.ElementTree as ET

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="å‹•ç”»é¸å‡ºé›†è¨ˆãƒ„ãƒ¼ãƒ«", layout="wide")

# --- å®šæ•°ãƒ»æ­£è¦è¡¨ç¾ ---
NICO_ID_RE = re.compile(r'(sm\d+|so\d+|nm\d+)')

def get_nico_metadata_api(video_id):
    """ãƒ‹ã‚³ãƒ‹ã‚³å‹•ç”»ã®å…¬å¼å¤–éƒ¨API(getthumbinfo)ã‹ã‚‰æƒ…å ±ã‚’å–å¾—ã™ã‚‹"""
    api_url = f"https://ext.nicovideo.jp/api/getthumbinfo/{video_id}"
    try:
        response = requests.get(api_url, timeout=5)
        if response.status_code == 200:
            root = ET.fromstring(response.text)
            if root.get('status') == 'ok':
                thumb = root.find('thumb')
                raw_date = thumb.find('first_retrieve').text
                dt = datetime.fromisoformat(raw_date)
                return {
                    'video_id': video_id,
                    'title': thumb.find('title').text,
                    'uploader': thumb.find('user_nickname').text if thumb.find('user_nickname') is not None else "å…¬å¼/ä¸æ˜",
                    'upload_date': dt.strftime('%Y-%m-%d %H:%M:%S'),
                    'url': f"https://www.nicovideo.jp/watch/{video_id}"
                }
    except Exception:
        pass
    return None

def get_video_metadata(url):
    """yt-dlpã‚’ä½¿ç”¨ã—ã¦æƒ…å ±ã‚’å–å¾—ã—ã€ãƒ‹ã‚³ãƒ‹ã‚³ã®å ´åˆã¯å°‚ç”¨APIã§è£œå®Œã™ã‚‹"""
    nico_ids = NICO_ID_RE.findall(url)
    if nico_ids:
        data = get_nico_metadata_api(nico_ids[0])
        if data:
            return [data]

    ydl_opts = {
        'quiet': True,
        'no_warnings': True,
        'extract_flat': True,
        'skip_download': True,
    }
    
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            
            if 'entries' in info:
                videos = []
                for entry in info['entries']:
                    if entry:
                        v_id = entry.get('id')
                        if v_id and (v_id.startswith('sm') or v_id.startswith('so') or v_id.startswith('nm')):
                            nico_data = get_nico_metadata_api(v_id)
                            if nico_data:
                                videos.append(nico_data)
                                continue
                        
                        videos.append({
                            'video_id': v_id or entry.get('url'),
                            'title': entry.get('title') or "[ã‚¿ã‚¤ãƒˆãƒ«å–å¾—ä¸å¯]",
                            'uploader': entry.get('uploader') or entry.get('channel') or "[æŠ•ç¨¿è€…ä¸æ˜]",
                            'upload_date': format_date(entry.get('upload_date')),
                            'url': entry.get('url') or (f"https://www.nicovideo.jp/watch/{v_id}" if v_id else url)
                        })
                return videos
            else:
                return [{
                    'video_id': info.get('id'),
                    'title': info.get('title') or "[ã‚¿ã‚¤ãƒˆãƒ«å–å¾—ä¸å¯]",
                    'uploader': info.get('uploader') or info.get('channel') or "[æŠ•ç¨¿è€…ä¸æ˜]",
                    'upload_date': format_date(info.get('upload_date')),
                    'url': url
                }]
    except Exception:
        return None

def format_date(date_str):
    """YYYYMMDD å½¢å¼ã‚’ YYYY-MM-DD ã«å¤‰æ›ï¼ˆä¸»ã«YouTubeç”¨ï¼‰"""
    if not date_str or not isinstance(date_str, str):
        return "[ä¸æ˜]"
    try:
        if len(date_str) == 8:
            dt = datetime.strptime(date_str, '%Y%m%d')
            return dt.strftime('%Y-%m-%d')
    except:
        pass
    return date_str

def process_data(df):
    """CSVå…¨ä½“ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    all_votes = []
    video_meta_cache = {} 
    
    progress_text = "å‹•ç”»æƒ…å ±ã‚’è§£æä¸­..."
    progress_bar = st.progress(0, text=progress_text)
    total_rows = len(df)

    for i, row in df.iterrows():
        # å®‰å…¨ã«å€¤ã‚’å–å¾—
        try:
            respondent = str(row.iloc[1]) if len(row) > 1 else "åŒ¿å"
            mylist_url = str(row.iloc[3]) if len(row) > 3 else ""
            ext_url = str(row.iloc[4]) if len(row) > 4 else ""
        except Exception:
            continue

        urls_to_process = [u.strip() for u in [mylist_url, ext_url] if u.strip() and str(u).lower() != 'nan']
        
        for url in urls_to_process:
            if url in video_meta_cache:
                results = video_meta_cache[url]
            else:
                results = get_video_metadata(url)
                video_meta_cache[url] = results
                time.sleep(0.05) 

            if results:
                for v in results:
                    all_votes.append({
                        'video_id': v['video_id'],
                        'title': v['title'],
                        'uploader': v['uploader'],
                        'upload_date': v['upload_date'],
                        'respondent': respondent
                    })
            else:
                # å–å¾—ä¸å¯ã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                nico_ids = NICO_ID_RE.findall(url)
                if nico_ids:
                    for n_id in nico_ids:
                        all_votes.append({
                            'video_id': n_id, 'title': "[å–å¾—ä¸å¯]", 'uploader': "[å–å¾—ä¸å¯]",
                            'upload_date': "[å–å¾—ä¸å¯]", 'respondent': respondent
                        })

        progress_bar.progress((i + 1) / total_rows, text=f"{progress_text} ({i+1}/{total_rows}è¡Œç›®)")

    if not all_votes: return None

    votes_df = pd.DataFrame(all_votes)
    # é›†è¨ˆå‡¦ç†
    ranking = votes_df.groupby('video_id').agg({
        'title': 'first',
        'upload_date': 'first',
        'uploader': 'first',
        'respondent': lambda x: sorted(list(set(x)))
    }).reset_index()

    ranking['count'] = ranking['respondent'].apply(len)
    ranking = ranking.sort_values(by=['count', 'video_id'], ascending=[False, True])
    ranking['é †ä½(è¢«ã‚Šãªã—)'] = range(1, len(ranking) + 1)
    ranking['é †ä½(è¢«ã‚Šã‚ã‚Š)'] = ranking['count'].rank(ascending=False, method='min').astype(int)
    
    return ranking

# --- UI ---
st.title("ğŸ“Š å‹•ç”»é¸å‡ºé›†è¨ˆãƒ»ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«")
st.markdown("""
- **ãƒ‹ã‚³ãƒ‹ã‚³å‹•ç”»**: æŠ•ç¨¿æ—¥æ™‚ï¼ˆç§’ã¾ã§ï¼‰ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
- **YouTube**: æŠ•ç¨¿æ—¥ï¼ˆå¹´æœˆæ—¥ã®ã¿ï¼‰ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
""")

uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['csv'])

if uploaded_file:
    content = uploaded_file.read()
    try:
        df_input = pd.read_csv(io.BytesIO(content), encoding='utf-8')
    except:
        df_input = pd.read_csv(io.BytesIO(content), encoding='shift-jis')

    st.write("ğŸ“‹ å…¥åŠ›CSVãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (5ä»¶)")
    st.dataframe(df_input.head())

    if st.button("ğŸš€ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œæˆã™ã‚‹"):
        try:
            result_df = process_data(df_input)
            
            if result_df is not None and not result_df.empty:
                # é¸å‡ºè€…ãƒªã‚¹ãƒˆã‚’å±•é–‹
                voter_lists = result_df['respondent'].tolist()
                max_voters = max([len(v) for v in voter_lists]) if voter_lists else 0
                
                # é¸å‡ºè€…ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–
                voters_df = pd.DataFrame(voter_lists, index=result_df.index)
                voters_df.columns = [f"é¸å‡ºè€…{i+1}" for i in range(voters_df.shape[1])]

                # æœ€çµ‚çš„ãªå‡ºåŠ›ã‚’çµåˆ
                final_output = pd.concat([
                    result_df[['é †ä½(è¢«ã‚Šãªã—)', 'é †ä½(è¢«ã‚Šã‚ã‚Š)', 'title', 'video_id', 'upload_date', 'uploader']],
                    voters_df
                ], axis=1)

                final_output = final_output.rename(columns={
                    'title': 'å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«', 'video_id': 'å‹•ç”»ID', 'upload_date': 'æŠ•ç¨¿æ—¥æ™‚', 'uploader': 'æŠ•ç¨¿è€…'
                })

                st.success(f"é›†è¨ˆå®Œäº†: {len(final_output)}ä»¶ã®å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
                
                # ç”»é¢è¡¨ç¤º
                st.subheader("ğŸ† é›†è¨ˆçµæœãƒ©ãƒ³ã‚­ãƒ³ã‚°")
                st.dataframe(final_output)
                
                # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                csv_data = final_output.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv_data, file_name=f"ranking_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv", mime='text/csv')
            else:
                st.warning("å‹•ç”»æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚CSVã®åˆ—ï¼ˆB:å›ç­”è€…, D:ãƒã‚¤ãƒªã‚¹ãƒˆ, E:ãƒªãƒ³ã‚¯ï¼‰ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        except Exception as e:
            st.error(f"ãƒ—ãƒ­ã‚°ãƒ©ãƒ å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.info("CSVã®å½¢å¼ã‚„åˆ—ã®ä¸¦ã³ãŒæƒ³å®šã¨ç•°ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
